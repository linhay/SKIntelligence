//
//  Created by ktiays on 2025/2/12.
//  Copyright (c) 2025 ktiays. All rights reserved.
//

import Foundation
import JSONSchema

/// https://platform.openai.com/docs/api-reference/chat/object
public struct ChatResponseBody: Decodable {
    /// A list of chat completion choices.
    /// Can be more than one if `n` on `ChatCompletionRequestBody` is greater than 1.
    public var choices: [ChatChoice]

    /// The Unix timestamp (in seconds) of when the chat completion was created.
    public let created: Int

    /// The model used for the chat completion.
    public let model: String

    /// Usage statistics for the completion request.
    public let usage: ChatUsage?

    /// This fingerprint represents the backend configuration that the model runs with.
    /// Can be used in conjunction with the `seed` request parameter to understand when
    /// backend changes have been made that might impact determinism.
    public let systemFingerprint: String?

    private enum CodingKeys: String, CodingKey {
        case choices
        case created
        case model
        case usage
        case systemFingerprint = "system_fingerprint"
    }

    public init(choices: [ChatChoice], created: Int, model: String, usage: ChatUsage? = nil, systemFingerprint: String? = nil) {
        self.choices = choices
        self.created = created
        self.model = model
        self.usage = usage
        self.systemFingerprint = systemFingerprint
    }
}

public struct ChatChoice: Decodable {
    /// The reason the model stopped generating tokens. This will be `stop` if the model hit a
    /// natural stop point or a provided stop sequence, `length` if the maximum number of
    /// tokens specified in the request was reached, `content_filter` if content was omitted
    /// due to a flag from our content filters, `tool_calls` if the model called a tool, or
    /// `function_call` (deprecated) if the model called a function.
    public var finishReason: String?

    /// A chat completion message generated by the model.
    public var message: ChoiceMessage

    private enum CodingKeys: String, CodingKey {
        case finishReason = "finish_reason"
        case message
    }

    public init(finishReason: String? = nil, message: ChoiceMessage) {
        self.finishReason = finishReason
        self.message = message
    }
}

public struct ChoiceMessage: Decodable {
    /// The contents of the message.
    public var content: String?

    /// The reasoning behin the message.
    public var reasoning: String?
    public var reasoningContent: String?

    /// The role of the author of this message.
    public let role: String

    /// The tool calls generated by the model, such as function calls.
    public let toolCalls: [ToolCall]?

    private enum CodingKeys: String, CodingKey {
        case content
        case reasoning
        case reasoningContent = "reasoning_content"
        case role
        case toolCalls = "tool_calls"
    }

    public init(
        content: String? = nil,
        reasoning: String? = nil,
        reasoningContent: String? = nil,
        role: String,
        toolCalls: [ToolCall]? = nil
    ) {
        self.content = content
        self.reasoning = reasoning
        self.reasoningContent = reasoningContent
        self.role = role
        self.toolCalls = toolCalls
    }
}

public struct ToolCall: Decodable {
    /// The ID of the tool call.
    public let id: String

    /// The type of the tool. Currently, only `function` is supported.
    public let type: String

    /// The function that the model instructs us to call
    public let function: Function
}

public struct Function: Decodable {
    /// The name of the function to call.
    public let name: String

    /// The arguments to call the function with, as generated by the model in JSON format. Note
    /// that the model does not always generate valid JSON, and may hallucinate parameters not
    /// defined by your function schema. Validate the arguments in your code before calling
    /// your function.
    ///
    /// Implementor's note: I no longer think the above warning is true, now that this launched:
    /// https://openai.com/index/introducing-structured-outputs-in-the-api/
    ///
    /// The keys of the `[String: Any]` dictionary are the argument names, e.g. `location` in the guide below.
    /// The values of the `[String: Any]` dictionary are the arguments values, e.g. `Bogot√°, Colombia` in this guide:
    /// https://platform.openai.com/docs/guides/function-calling.
    public let arguments: [String: Any]?

    /// The raw arguments string, unmapped to a `[String: Any]`. The unmapped string is useful for
    /// continuing the converstation with the model. The model expects you to feed the raw argument string
    /// back to the model on susbsequent requests.
    public let argumentsRaw: String?

    private enum CodingKeys: CodingKey {
        case name
        case arguments
    }

    public init(from decoder: any Decoder) throws {
        let container = try decoder.container(keyedBy: CodingKeys.self)
        name = try container.decode(String.self, forKey: .name)
        if let argumentsRaw = try? container.decode(String.self, forKey: .arguments) {
            self.argumentsRaw = argumentsRaw
            let data = argumentsRaw.data(using: .utf8)!
            arguments = try (JSONDecoder().decode([String: JSONValue].self, from: data)).untypedDictionary
        } else {
            argumentsRaw = nil
            arguments = nil
        }
    }
}
